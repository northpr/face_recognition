{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "import torchvision.models as models\n",
    "import os\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data transformation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/for_model\"\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in [\"train\",\"val\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset ImageFolder\n",
       "     Number of datapoints: 2728\n",
       "     Root location: ../data/for_model/train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear)\n",
       "                RandomHorizontalFlip(p=0.5)\n",
       "                ToTensor()\n",
       "                Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "            ),\n",
       " 'val': Dataset ImageFolder\n",
       "     Number of datapoints: 363\n",
       "     Root location: ../data/for_model/val\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=256, interpolation=bilinear, max_size=None, antialias=None)\n",
       "                CenterCrop(size=(224, 224))\n",
       "                ToTensor()\n",
       "                Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "            )}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x1296a4e50>,\n",
       " 'val': <torch.utils.data.dataloader.DataLoader at 0x1296a4e20>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle =True, num_workers=4) for x in [\"train\",\"val\"]}\n",
    "dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Andy_Samberg',\n",
       " 'Chris_Evans',\n",
       " 'Dominic_Purcell',\n",
       " 'Gwyneth_Paltrow',\n",
       " 'Henry_Cavil',\n",
       " 'Hugh_Jackman',\n",
       " 'Inbar_Lavi',\n",
       " 'Keanu_Reeves',\n",
       " 'Krysten_Ritter',\n",
       " 'Leonardo_DiCaprio',\n",
       " 'Penn_Badgley',\n",
       " 'Tom_Hardy',\n",
       " 'Zendaya',\n",
       " 'Zoe_Saldana',\n",
       " 'amber_heard',\n",
       " 'camila_mendes',\n",
       " 'gal_gadot',\n",
       " 'grant_gustin',\n",
       " 'kiernen_shipka']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_siEd = {x: len(image_datasets[x]) for x in [\"train\", \"val\"]}\n",
    "class_names = image_datasets[\"train\"].classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the pre-trained model and replace the last fylly connected layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minception_resnet_v1\u001b[39;00m \u001b[39mimport\u001b[39;00m InceptionResnetV1\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtf_slim\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mslim\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39mvggface2(pretrained\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, classify\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, num_class\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(class_names))\n",
      "File \u001b[0;32m~/Desktop/Code/face_recognition/nbs/models/inception_resnet_v1.py:27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[1;32m     26\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontrib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mslim\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mslim\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39m# Inception-Resnet-A\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mblock35\u001b[39m(net, scale\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m, activation_fn\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mrelu, scope\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, reuse\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.contrib'"
     ]
    }
   ],
   "source": [
    "from models.inception_resnet_v1 import InceptionResnetV1\n",
    "import tf_slim as slim\n",
    "\n",
    "model = models.vggface2(pretrained=True, classify=False, num_class= len(class_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "718a34663a832fe82a5544c8eaf8a2021a5d6e1be4c2f20e59187dcf7872c602"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
